
import json
import os
import sys
from .jy_wrapper import JyProject
import pyJianYingDraft as draft

def apply_smart_zoom(project: JyProject, video_segment, events_json_path: str, zoom_scale=150, zoom_duration_us=500000):
    """
    æ ¹æ®è®°å½•çš„ events.json è‡ªåŠ¨ä¸ºè§†é¢‘ç‰‡æ®µæ·»åŠ ç¼©æ”¾å…³é”®å¸§ (ç±»ä¼¼äº§å“æ¼”ç¤ºæ•ˆæœ)
    
    Args:
        project: JyProject å®ä¾‹
        video_segment: è¦åº”ç”¨ç¼©æ”¾çš„è§†é¢‘ç‰‡æ®µå¯¹è±¡
        events_json_path: å½•åˆ¶æ—¶ç”Ÿæˆçš„ _events.json è·¯å¾„
        zoom_scale: ç¼©æ”¾æ¯”ä¾‹ (%)
        zoom_duration_us: ç¼©æ”¾åŠ¨ç”»æŒç»­æ—¶é—´ (å¾®ç§’), é»˜è®¤ 0.5s
    """
    if not os.path.exists(events_json_path):
        print(f"âŒ Events file not found: {events_json_path}")
        return

    with open(events_json_path, 'r', encoding='utf-8') as f:
        events = json.load(f)

    # æå–ç‚¹å‡»äº‹ä»¶
    click_events = [e for e in events if e['type'] == 'click']
    if not click_events:
        print("â„¹ï¸ No click events found in JSON.")
        return

    print(f"ğŸ¯ Found {len(click_events)} click events. Applying smart zoom keyframes...")
    
    # æå–æ‰€æœ‰ç§»åŠ¨äº‹ä»¶ä¾›åç»­æŸ¥è¯¢
    move_events = [e for e in events if e.get('type') == 'move']
    
    # å°†ç‚¹å‡»äº‹ä»¶åˆ†ç»„ (Session-based)
    grouped_events = []
    if click_events:
        current_group = [click_events[0]]
        for i in range(1, len(click_events)):
            prev_time = click_events[i-1]['time']
            curr_time = click_events[i]['time']
            if (curr_time - prev_time) <= 5.0:
                current_group.append(click_events[i])
            else:
                grouped_events.append(current_group)
                current_group = [click_events[i]]
        grouped_events.append(current_group)

    print(f"ğŸ”„ Grouped into {len(grouped_events)} zoom sessions.")

    from pyJianYingDraft.keyframe import KeyframeProperty as KP

    # å‡†å¤‡çº¢ç‚¹ç´ æè·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    skill_root = os.path.dirname(current_dir)
    marker_path = os.path.join(skill_root, "assets", "click_marker.png")
    
    # ç¼©æ”¾å‚æ•°
    scale_val = float(zoom_scale) / 100.0
    ZOOM_IN_US = 300000    # 0.3s
    HOLD_US = 5000000      # 5.0s
    ZOOM_OUT_US = 600000   # 0.6s
    
    # è§†å£è¾¹ç•Œ (ç›¸å¯¹äºå½’ä¸€åŒ–åæ ‡ä¸­å¿ƒ 0.5, 0.5)
    # å½“ç¼©æ”¾å€ç‡ä¸º S æ—¶ï¼Œå±å¹•å¯è§èŒƒå›´åœ¨åŸå§‹ç´ æä¸­çš„å®½åº¦æ˜¯ 1.0 / S
    # å› æ­¤ä¸­å¿ƒç‚¹å‘å·¦å‘å³å„å¯è§ 0.5 / S
    viewport_half_w = 0.5 / scale_val
    viewport_half_h = 0.5 / scale_val

    def get_clamped_pos(tx, ty, scale):
        """
        è®¡ç®—é’³åˆ¶åçš„ä½ç½®ï¼Œé˜²æ­¢å‡ºç°é»‘è¾¹ã€‚
        tx, ty: ç›®æ ‡ç‚¹ç›¸å¯¹äºä¸­å¿ƒç‚¹çš„å½’ä¸€åŒ–åç§» (-1 to 1)
        scale: ç¼©æ”¾å€ç‡ (ä¾‹å¦‚ 1.5)
        è¿”å›: (pos_x, pos_y) ä¾›å‰ªæ˜ ä½¿ç”¨
        """
        px = -tx * scale
        py = -ty * scale
        
        # è¾¹ç•Œæ§åˆ¶ï¼špx å¿…é¡»åœ¨ [-(scale-1), (scale-1)] ä¹‹é—´
        limit = max(0.0, scale - 1.0)
        px = max(-limit, min(px, limit))
        py = max(-limit, min(py, limit))
        return px, py

    for group in grouped_events:
        # --- 1. Start Phase (æ•´ä½“è¿›åœº) ---
        first_event = group[0]
        t0_us = int(first_event['time'] * 1000000)
        t_start = max(0, t0_us - ZOOM_IN_US)
        
        video_segment.add_keyframe(KP.uniform_scale, t_start, 1.0)
        video_segment.add_keyframe(KP.position_x, t_start, 0.0)
        video_segment.add_keyframe(KP.position_y, t_start, 0.0)
        
        # è®°å½•å½“å‰çš„æ‘„åƒæœºä¸­å¿ƒ (å½’ä¸€åŒ–åæ ‡ 0-1)
        current_cam_x = 0.5
        current_cam_y = 0.5

        # éå†ç»„å†…æ¯ä¸ªç‚¹å‡»äº‹ä»¶ï¼Œä»¥åŠç‚¹å‡»ä¹‹é—´çš„ Move äº‹ä»¶
        for i, event in enumerate(group):
            t_curr_us = int(event['time'] * 1000000)
            
            # --- A. æ·»åŠ çº¢ç‚¹æ ‡è®° (Sticker) ---
            if os.path.exists(marker_path):
                try:
                    project.add_sticker_at(marker_path, t_curr_us, 500000) 
                except:
                    pass

            # --- B. å¤„ç†ç‚¹å‡»æœ¬èº«çš„å…³é”®å¸§ ---
            target_tx = (event['x'] - 0.5) * 2
            target_ty = (0.5 - event['y']) * 2
            
            pos_x, pos_y = get_clamped_pos(target_tx, target_ty, scale_val)
            
            # æ›´æ–°æ‘„åƒæœºä¸­å¿ƒï¼ˆåŸºäºå®é™…çš„å¹³ç§»é‡åæ¨ï¼Œå› ä¸ºå¯èƒ½è¢«é’³åˆ¶äº†ï¼‰
            current_cam_x = -pos_x / (2 * scale_val) + 0.5
            current_cam_y = 0.5 - pos_y / (2 * scale_val)

            if i == 0:
                video_segment.add_keyframe(KP.uniform_scale, t_curr_us, scale_val)
                video_segment.add_keyframe(KP.position_x, t_curr_us, pos_x)
                video_segment.add_keyframe(KP.position_y, t_curr_us, pos_y)
            else:
                prev_event = group[i-1]
                t_prev_us = int(prev_event['time'] * 1000000)
                interval_moves = [m for m in move_events if prev_event['time'] < m['time'] < event['time']]
                
                for m in interval_moves:
                    t_m_us = int(m['time'] * 1000000)
                    is_out_x = abs(m['x'] - current_cam_x) > (viewport_half_w * 0.85)
                    is_out_y = abs(m['y'] - current_cam_y) > (viewport_half_h * 0.85)
                    
                    if is_out_x or is_out_y:
                        m_tx = (m['x'] - 0.5) * 2
                        m_ty = (0.5 - m['y']) * 2
                        m_px, m_py = get_clamped_pos(m_tx, m_ty, scale_val)
                        video_segment.add_keyframe(KP.position_x, t_m_us, m_px)
                        video_segment.add_keyframe(KP.position_y, t_m_us, m_py)
                        current_cam_x = -m_px / (2 * scale_val) + 0.5
                        current_cam_y = 0.5 - m_py / (2 * scale_val)

                video_segment.add_keyframe(KP.uniform_scale, t_curr_us, scale_val)
                video_segment.add_keyframe(KP.position_x, t_curr_us, pos_x)
                video_segment.add_keyframe(KP.position_y, t_curr_us, pos_y)

        # --- 3. End Phase (åŠ¨æ€å»¶é•¿åœç•™æœŸ) ---
        last_event = group[-1]
        
        # åˆå§‹æˆªæ­¢æ—¶é—´ = æœ€åä¸€æ¬¡ç‚¹å‡» + 3s
        last_activity_time = last_event['time']
        
        # ç­›é€‰å‡ºæœ€åä¸€æ¬¡ç‚¹å‡»ä¹‹åçš„æ‰€æœ‰ç§»åŠ¨äº‹ä»¶
        potential_moves = [m for m in move_events if m['time'] > last_activity_time]
        
        valid_post_moves = []
        for m in potential_moves:
            # å¦‚æœè¯¥ç§»åŠ¨å‘ç”Ÿåœ¨å½“å‰å€’è®¡æ—¶çª—å£å†… (è·ç¦»ä¸Šä¸€æ¬¡æ´»åŠ¨ <= 3s)
            # åˆ™â€œç»­è´¹â€ 3sï¼Œæ›´æ–°æœ€åæ´»åŠ¨æ—¶é—´
            if m['time'] - last_activity_time <= 5.0:
                last_activity_time = m['time']
                valid_post_moves.append(m)
            else:
                # ä¸€æ—¦æ–­æ¡£è¶…è¿‡ 3sï¼Œåˆ™è®¤ä¸ºæ“ä½œç»“æŸ
                break
        
        # å¤„ç†è¿™äº›å»¶é•¿æœŸçš„ç§»åŠ¨è·Ÿéš
        for m in valid_post_moves:
             t_m_us = int(m['time'] * 1000000)
             
             is_out_x = abs(m['x'] - current_cam_x) > (viewport_half_w * 0.85)
             is_out_y = abs(m['y'] - current_cam_y) > (viewport_half_h * 0.85)
             
             if is_out_x or is_out_y:
                # è§¦å‘è·Ÿéš
                m_tx = (m['x'] - 0.5) * 2
                m_ty = (0.5 - m['y']) * 2
                m_px, m_py = get_clamped_pos(m_tx, m_ty, scale_val)
                
                video_segment.add_keyframe(KP.position_x, t_m_us, m_px)
                video_segment.add_keyframe(KP.position_y, t_m_us, m_py)
                
                current_cam_x = -m_px / (2 * scale_val) + 0.5
                current_cam_y = 0.5 - m_py / (2 * scale_val)

        # æœ€ç»ˆç»“æŸæ—¶é—´ = (æœ€åä¸€ä¸ªæœ‰æ•ˆæ´»åŠ¨çš„æ—¶åˆ») + 3s
        # æˆ–è€…æ˜¯: last_activity_time å·²ç»æ˜¯æœ€åä¸€ä¸ªæ´»åŠ¨äº†ï¼Œé‚£ä¹ˆå€’è®¡æ—¶æ˜¯ä¸æ˜¯æŒ‡â€œé™æ­¢ 3s åé€€å‡ºâ€ï¼Ÿ
        # "é»˜è®¤3sä¸ç¼©æ”¾ï¼ŒæœŸé—´...å†æ¬¡å€’è®¡æ—¶" -> æ„å‘³ç€ Zoom Out å‘ç”Ÿåœ¨ last_activity_time + 3s
        
        t_hold_end = int((last_activity_time + 5.0) * 1000000)
        
        # è·å–æœ€åæ—¶åˆ»çš„å„ç§å˜é‡ç”¨äºä¿æŒçŠ¶æ€
        # æ³¨æ„: è¿™é‡Œçš„ current_cam_x å·²ç»è¢«ä¸Šé¢çš„å¾ªç¯æ›´æ–°åˆ°æœ€æ–°äº†
        final_px, final_py = get_clamped_pos((current_cam_x - 0.5) * 2, (0.5 - current_cam_y) * 2, scale_val)

        # æ·»åŠ  Hold ç»“æŸå¸§
        video_segment.add_keyframe(KP.uniform_scale, t_hold_end, scale_val)
        video_segment.add_keyframe(KP.position_x, t_hold_end, final_px)
        video_segment.add_keyframe(KP.position_y, t_hold_end, final_py)

        # æ¢å¤å…¨æ™¯
        t_restore = t_hold_end + ZOOM_OUT_US
        video_segment.add_keyframe(KP.uniform_scale, t_restore, 1.0)
        video_segment.add_keyframe(KP.position_x, t_restore, 0.0)
        video_segment.add_keyframe(KP.position_y, t_restore, 0.0)

    print("âœ… Smart zoom keyframes applied successfully.")

if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    if len(sys.argv) < 3:
        print("Usage: python smart_zoomer.py <project_name> <video_path> <events_json>")
        sys.exit(1)
        
    proj_name = sys.argv[1]
    video_path = sys.argv[2]
    json_path = sys.argv[3]
    
    p = JyProject(proj_name)
    seg = p.add_media_safe(video_path, "0s")
    apply_smart_zoom(p, seg, json_path)
    p.save()
