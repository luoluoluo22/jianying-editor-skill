import os
import sys
import json
import subprocess
import time
import re

# ==========================================
# 1. åŸºç¡€é…ç½® (Paths & Config)
# ==========================================
# ==========================================
# 1. åŸºç¡€é…ç½® (Paths & Config)
# ==========================================
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
# è„šæœ¬è·¯å¾„æ¢æµ‹ï¼šæœŸæœ›æŒ‡å‘ .agent/skills
# å½“å‰æ–‡ä»¶åœ¨ .agent/skills/jianying-editor/examples/ ä¸‹ï¼Œå‘ä¸Š 2 çº§å³ä¸º skills æ ¹ç›®å½•
SKILL_ROOT = os.path.dirname(os.path.dirname(PROJECT_ROOT))

# å…œåº•æ ¡éªŒï¼šå¦‚æœæ²¡æ‰¾åˆ° antigravity-api-skillï¼Œåˆ™å°è¯•ä»å½“å‰å·¥ä½œç›®å½•æŸ¥æ‰¾
if not os.path.exists(os.path.join(SKILL_ROOT, "antigravity-api-skill")):
    alternative_path = os.path.abspath(".agent/skills")
    if os.path.exists(os.path.join(alternative_path, "antigravity-api-skill")):
        SKILL_ROOT = alternative_path

# é¡¹ç›®æ ¹ç›®å½• (å³ .agent çš„ä¸Šçº§ç›®å½•)
WORKSPACE_ROOT = os.path.dirname(os.path.dirname(SKILL_ROOT))

CHAT_SCRIPT = os.path.join(SKILL_ROOT, "antigravity-api-skill", "scripts", "chat.py")
MF_SCRIPT = os.path.join(SKILL_ROOT, "antigravity-api-skill", "scripts", "video_analyzer.py")
JY_SCRIPT_DIR = os.path.join(SKILL_ROOT, "jianying-editor", "scripts")


# ==========================================
# 2. å·¥å…·å‡½æ•° (Utilities)
# ==========================================
def safe_decode(bytes_content):
    for enc in ['utf-8', 'gbk', 'utf-16']:
        try: return bytes_content.decode(enc)
        except: continue
    return bytes_content.decode('utf-8', errors='replace')

def parse_srt_time(time_str):
    try:
        parts = time_str.replace(',', '.').split(':')
        if len(parts) == 3:
            h, m, s = map(float, parts)
            return h * 3600 + m * 60 + s
    except: pass
    return 0.0

def parse_srt_content(content):
    content = content.replace('\r\n', '\n').replace('\r', '\n')
    lines = [l.strip() for l in content.split('\n') if l.strip()]
    subs = []
    i = 0
    while i < len(lines):
        if lines[i].isdigit() and i+1 < len(lines) and '-->' in lines[i+1]:
            time_line = lines[i+1]
            text_lines, curr = [], i+2
            while curr < len(lines) and not lines[curr].isdigit():
                text_lines.append(lines[curr]); curr += 1
            
            times = time_line.split(' --> ')
            start_str = times[0].strip()
            end_str = times[1].strip() if len(times) > 1 else start_str
            
            start_sec = parse_srt_time(start_str)
            end_sec = parse_srt_time(end_str)
            
            subs.append({
                "index": int(lines[i]),
                "start": start_sec,
                "end": end_sec,
                "duration": end_sec - start_sec,
                "text": " ".join(text_lines).strip()
            })
            i = curr; continue
        i += 1
    return subs

# ==========================================
# 3. æ ¸å¿ƒæµç¨‹ç±» (Workflow Engine)
# ==========================================
class VideoAutoEditor:
    def __init__(self, main_input, material_inputs, project_name, srt_input=None, bg_image=None):
        self.main_input = main_input
        self.material_inputs = material_inputs if isinstance(material_inputs, list) else [material_inputs]
        self.project_name = project_name
        self.srt_input = srt_input
        self.bg_image = bg_image
        
        # å†…éƒ¨ä¸´æ—¶/ç¼“å­˜è·¯å¾„ (ç°åœ¨æŒ‡å‘ WORKSPACE_ROOT)
        self.temp_srt = srt_input if srt_input else os.path.join(WORKSPACE_ROOT, "auto_generated_subs.srt")
        self.analysis_json = os.path.join(WORKSPACE_ROOT, "auto_material_analysis.json")
        self.matches_json = os.path.join(WORKSPACE_ROOT, "auto_ai_matches.json")
        
        if JY_SCRIPT_DIR not in sys.path:
            sys.path.insert(0, JY_SCRIPT_DIR)

    def step1_recognize_subtitles(self):
        # å¦‚æœç”¨æˆ·æä¾›äº† SRT æ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨
        if self.srt_input and os.path.exists(self.srt_input):
            print(f">>> [Step 1] ä½¿ç”¨å·²æœ‰å­—å¹•æ–‡ä»¶: {self.srt_input}")
            self.temp_srt = self.srt_input
            return

        # å¦‚æœå­—å¹•å·²ç»ç”Ÿæˆåœ¨ç¼“å­˜ä¸­ï¼Œè·³è¿‡
        if os.path.exists(self.temp_srt):
            print(f">>> [Step 1] è·³è¿‡ï¼šå­—å¹•ç¼“å­˜å·²å­˜åœ¨: {self.temp_srt}")
            return
            
        if not self.main_input:
            raise ValueError("æœªæä¾›ä¸»è§†é¢‘/éŸ³é¢‘ï¼Œæ— æ³•ç”Ÿæˆå­—å¹•ã€‚è¯·æä¾› --video æˆ– --srt å‚æ•°ã€‚")

        print(f"[Step 1] æ­£åœ¨è¯†åˆ«éŸ³é¢‘ä¸­çš„å­—å¹• (Gemini 3 Flash): {os.path.basename(self.main_input)}...")
        
        # ä¼˜åŒ–åçš„æç¤ºè¯ï¼šè¦æ±‚ç²¾ç¡®å¯¹é½å¹¶å»é™¤å¤šä½™è¾“å‡º
        prompt = (
            "Please transcribe the audio from the file strictly into SRT format. \n"
            "CRITICAL: The timestamps must accurately match the speech in the audio. \n"
            "One sentence per block. Output ONLY the SRT content. No preamble, no markers."
        )
        
        cmd = [sys.executable, CHAT_SCRIPT, prompt, "gemini-3-flash", self.main_input]
        result = subprocess.run(cmd, capture_output=True)
        raw_content = safe_decode(result.stdout)
        
        # æå–çœŸæ­£çš„ SRT éƒ¨åˆ† (å¯»æ‰¾æ•°å­—åºå· -> æ—¶é—´æˆ³ -> æ–‡æœ¬çš„ç»“æ„)
        srt_match = re.findall(r'(\d+\s+\d{2}:\d{2}:\d{2},\d{3} --> \d{2}:\d{2}:\d{2},\d{3}.*?)(?=\d+\s+\d{2}:\d{2}:\d{2},\d{3}|$)', raw_content, re.DOTALL)
        if srt_match:
            srt_content = "\n\n".join([m.strip() for m in srt_match])
        else:
            # å…œåº•æ–¹æ¡ˆï¼šå°è¯•å¯»æ‰¾åˆ†éš”ç¬¦
            parts = raw_content.split('------------------------------')
            srt_content = parts[1].strip() if len(parts) >= 2 else raw_content.strip()
            
        with open(self.temp_srt, "w", encoding="utf-8") as f: f.write(srt_content)
        print(f"âœ… å­—å¹•å·²ç”Ÿæˆå¹¶æ¸…æ´—: {self.temp_srt}")

    def step2_analyze_materials(self, limit=None):
        print(f"[Step 2] æ±‡æ€»ä¸åˆ†æç´ æåº“ (è¾“å…¥æº: {len(self.material_inputs)})...")
        
        # 1. æ‰«ææ‰€æœ‰è¾“å…¥æºè·å–æ–‡ä»¶åˆ—è¡¨
        all_video_paths = []
        for inp in self.material_inputs:
            path = os.path.abspath(inp)
            if os.path.isfile(path):
                if path.lower().endswith(('.mp4', '.mov')):
                    all_video_paths.append(path)
            elif os.path.isdir(path):
                for root, dirs, files in os.walk(path):
                    for f in files:
                        if f.lower().endswith(('.mp4', '.mov')) and "æ•°å­—äºº" not in f:
                            all_video_paths.append(os.path.join(root, f))
        
        if limit:
            all_video_paths = all_video_paths[:limit]
            
        print(f"    - å…±å‘ç° {len(all_video_paths)} ä¸ªè§†é¢‘æ–‡ä»¶ã€‚")

        # 2. åŠ è½½ç°æœ‰ç¼“å­˜
        existing_results = []
        if os.path.exists(self.analysis_json):
            try:
                with open(self.analysis_json, "r", encoding="utf-8") as f:
                    existing_results = json.load(f)
            except:
                existing_results = []
        
        # å»ºç«‹ç´¢å¼•ï¼šä»¥ç»å¯¹è·¯å¾„ä½œä¸º Keyï¼Œé˜²æ­¢åŒåæ–‡ä»¶å†²çª
        cache_map = {item.get('path', item.get('filename')): item for item in existing_results}
        
        final_results = []
        from jy_wrapper import draft
        
        for path in all_video_paths:
            filename = os.path.basename(path)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜
            if path in cache_map:
                print(f"    - è·³è¿‡å·²åˆ†æç´ æ: {filename}")
                final_results.append(cache_map[path])
                continue

            if not os.path.exists(path):
                print(f"    - æ–‡ä»¶æœªæ‰¾åˆ°: {path}")
                continue
                
            print(f"    - æ­£åœ¨åˆ†ææ–°ç´ æ: {filename}...")
            # è·å–æ—¶é•¿
            try:
                dur = draft.VideoMaterial(path).duration / 1000000.0
            except:
                dur = 0
                
            # AI è¯†åˆ«å†…å®¹
            prompt = "Analyze this cooking clip. Provide a JSON: {'tags': ['keyword1', 'keyword2'], 'desc': 'summary'}. No markdown."
            cmd = [sys.executable, MF_SCRIPT, path, prompt]
            ans = subprocess.run(cmd, capture_output=True)
            try:
                clean_ans = safe_decode(ans.stdout).strip()
                start_idx = clean_ans.find('{')
                end_idx = clean_ans.rfind('}')
                analysis = json.loads(clean_ans[start_idx:end_idx+1])
                
                new_entry = {"filename": filename, "path": path, "duration": dur, "analysis": analysis}
                final_results.append(new_entry)
                
                # æ¯åˆ†æå®Œä¸€ä¸ªå°±è¿½åŠ ä¿å­˜
                cache_map[path] = new_entry
                with open(self.analysis_json, "w", encoding="utf-8") as out:
                    json.dump(list(cache_map.values()), out, indent=2, ensure_ascii=False)
                print(f"   âœ… {filename} åˆ†æå®Œæˆå¹¶å·²å­˜å…¥ç¼“å­˜ã€‚")
            except: 
                print(f"   âš ï¸ {filename} åˆ†æå¤±è´¥ï¼Œè·³è¿‡ã€‚")
        
        return final_results

    def step3_ai_match(self, materials_data):
        if os.path.exists(self.matches_json):
            print(f">>> [Step 3] è·³è¿‡ï¼šAI è¯­ä¹‰åŒ¹é…ç»“æœå·²å­˜åœ¨: {self.matches_json}")
            with open(self.matches_json, "r", encoding="utf-8") as f:
                return json.load(f)

        print("[Step 3] æ­£åœ¨è®© AI å¤„ç†ç´ æä¸å­—å¹•çš„è¯­ä¹‰åŒ¹é…...")
        
        with open(self.temp_srt, 'r', encoding='utf-8') as f:
            srt_content = f.read()
        
        # å‡†å¤‡ç¼©å‡ç‰ˆçš„ç´ æä¿¡æ¯ä¼ ç»™ AI
        materials_summary = []
        for i, m in enumerate(materials_data):
            materials_summary.append({
                "id": i,
                "file": m["filename"],
                "desc": m["analysis"].get("desc", ""),
                "tags": m["analysis"].get("tags", []),
                "dur": m["duration"]
            })
            
        prompt = (
            "You are a professional video editor. Match the best video clips to the provided subtitles.\n"
            "MATERIALS:\n" + json.dumps(materials_summary, ensure_ascii=False) + "\n\n"
            "SUBTITLES (SRT):\n" + srt_content + "\n\n"
            "TASK:\n"
            "1. Analyze the meaning of each subtitle line.\n"
            "2. Select the most appropriate video clip from the list for that specific segment.\n"
            "3. CRITICAL RULE: Each material ID can only be used ONCE throughout the whole video. If you run out of unique materials, leave the remaining subtitles unmatched.\n"
            "4. Return a JSON array of objects. Example: [{\"srt_idx\": 1, \"id\": 0}]\n"
            "5. Output ONLY the JSON array, no explanation."
        )
        
        cmd = [sys.executable, CHAT_SCRIPT, prompt, "gemini-3-flash"]
        ans = subprocess.run(cmd, capture_output=True)
        resp = safe_decode(ans.stdout).strip()
        
        try:
            # å¼ºåŒ– JSON æå–é€»è¾‘ï¼šè·å–åˆ†éš”ç¬¦ä¹‹é—´çš„å†…å®¹
            parts = resp.split('------------------------------')
            if len(parts) >= 2:
                # ä¼˜å…ˆå–ç¬¬ 2 éƒ¨åˆ†ï¼ˆé€šå¸¸æ˜¯æµå¼è¾“å‡ºçš„æ­£æ–‡ï¼‰
                resp = parts[1]
            
            start_idx = resp.find('[')
            end_idx = resp.rfind(']')
            if start_idx == -1 or end_idx == -1:
                raise ValueError("æœªåœ¨ AI å“åº”ä¸­æ‰¾åˆ° JSON æ•°ç»„")
            
            clean_resp = resp[start_idx:end_idx+1]
            matches = json.loads(clean_resp)
            
            # ä¿å­˜åŒ¹é…ç»“æœåˆ°ç¼“å­˜
            with open(self.matches_json, "w", encoding="utf-8") as f:
                json.dump(matches, f, indent=2, ensure_ascii=False)
                
            print(f"âœ… AI åŒ¹é…å®Œæˆå¹¶å·²ä¿å­˜è‡³ç¼“å­˜ï¼Œå…±é€‰å®š {len(matches)} ä¸ªåŒ¹é…ç‚¹ã€‚")
            return matches
        except Exception as e:
            print(f"AI åŒ¹é…è§£æå¤±è´¥: {e}\nå“åº”å†…å®¹æ‘˜è¦: {resp[:200]}...")
            return []

    def step4_assemble_project(self, materials_data, ai_matches):
        print(f"[Step 4] ç»„è£…å‰ªè¾‘å·¥ç¨‹: {self.project_name}...")
        from jy_wrapper import JyProject
        
        # åŠ è½½å¹¶è§£æå­—å¹•ä»¥è·å–ç²¾ç¡®æ—¶é—´
        with open(self.temp_srt, 'r', encoding='utf-8') as f:
            subs_list = parse_srt_content(f.read())

        project = JyProject(self.project_name, width=1080, height=1920)
        
        # 1. åˆ¤å®šä¸»è¾“å…¥ç±»å‹
        is_main_video = False
        if self.main_input and os.path.exists(self.main_input):
            ext = self.main_input.lower().split('.')[-1]
            if ext in ['mp4', 'mov', 'mkv', 'avi']:
                is_main_video = True

        # 2. ç¡®å®šå·¥ç¨‹æ€»æ—¶é•¿
        total_dur = subs_list[-1]['end'] if subs_list else 10.0
        
        # 3. å¤„ç†èƒŒæ™¯ä¸ä¸»è½¨é“é€»è¾‘
        # åœºæ™¯ A: ä¸»è¾“å…¥æ˜¯è§†é¢‘ -> è§†é¢‘å³æ˜¯èƒŒæ™¯ï¼Œä¹Ÿæ˜¯ä¸»è¦å†…å®¹
        if is_main_video:
            print(f"   ğŸ¥ æ·»åŠ ä¸»è§†é¢‘è½¨é“: {os.path.basename(self.main_input)}")
            project.add_media_safe(self.main_input)
            
            # å¦‚æœç”¨æˆ·å¼ºåˆ¶æŒ‡å®šäº†å…¶ä»–çš„ bg_image (éé»˜è®¤é¢œè‰²)ï¼Œæ¯”å¦‚ä¸€ä¸ªå åŠ å±‚å›¾ï¼Œå¯ä»¥é¢å¤–å¤„ç†
            if self.bg_image and self.bg_image not in ["white", "black"] and os.path.exists(self.bg_image):
                 print(f"   ğŸ–¼ï¸ æ·»åŠ å åŠ å±‚/èƒŒæ™¯å›¾: {os.path.basename(self.bg_image)}")
                 project.add_media_safe(self.bg_image, duration=f"{total_dur}s", track_name="Background_Layer")
        
        # åœºæ™¯ B: ä¸»è¾“å…¥æ˜¯éŸ³é¢‘ (æˆ–æ— è¾“å…¥) -> éœ€è¦å¡«å……èƒŒæ™¯
        else:
            bg_to_use = self.bg_image if self.bg_image else "white"
            bg_val = bg_to_use.lower()
            
            if bg_val == "white":
                print(f"   â¬œ å¡«å……å†…ç½®çº¯ç™½èƒŒæ™¯ (æ—¶é•¿: {total_dur}s)")
                project.add_color_strip("#FFFFFF", duration=f"{total_dur}s")
            elif bg_val == "black":
                print(f"   â¬› å¡«å……å†…ç½®çº¯é»‘èƒŒæ™¯ (æ—¶é•¿: {total_dur}s)")
                project.add_color_strip("#000000", duration=f"{total_dur}s")
            elif os.path.exists(bg_to_use):
                print(f"   ğŸ–¼ï¸ å¡«å……ä¸»èƒŒæ™¯å›¾: {os.path.basename(bg_to_use)} (æ—¶é•¿: {total_dur}s)")
                project.add_media_safe(bg_to_use, duration=f"{total_dur}s")
            else:
                # å…œåº•ï¼šé»‘è‰²
                project.add_color_strip("#000000", duration=f"{total_dur}s")

            # æ·»åŠ ä¸»éŸ³é¢‘ (å¦‚æœæ˜¯éŸ³é¢‘æ–‡ä»¶)
            if self.main_input and os.path.exists(self.main_input):
                 print(f"   ğŸµ æ·»åŠ ä¸»é…éŸ³è½¨é“: {os.path.basename(self.main_input)}")
                 project.add_media_safe(self.main_input, track_name="Main_Vocal")
        
        project.import_subtitles(self.temp_srt)
        
        # --- ä¼˜åŒ–ç‚¹ï¼šå¯¹åŒ¹é…ç»“æœè¿›è¡Œå»é‡ï¼Œç¡®ä¿æ¯ä¸ª srt_idx åªæœ‰ä¸€ä¸ªç´ æ ---
        unique_matches = {}
        for m in ai_matches:
            idx = m.get("srt_idx")
            if idx not in unique_matches:
                unique_matches[idx] = m
        
        added_count = 0
        target_track = "B-Roll_Main" # ç»Ÿä¸€ä½¿ç”¨ä¸€ä¸ªä¸»è¦ç©ºé•œè½¨é“
        used_materials = set() # è®°å½•å·²ä½¿ç”¨çš„ç´ æ ID
        
        for idx in sorted(unique_matches.keys()):
            match = unique_matches[idx]
            m_id = match.get("id")
            
            # æ ¡éªŒç´ ææ˜¯å¦å·²è¢«ä½¿ç”¨
            if m_id in used_materials:
                print(f"    - è·³è¿‡é‡å¤ä½¿ç”¨çš„ç´ æ: ID {m_id} (Subtitle {idx})")
                continue

            if 1 <= idx <= len(subs_list) and m_id is not None and 0 <= m_id < len(materials_data):
                sub = subs_list[idx-1]
                m_info = materials_data[m_id]
                path = m_info['path']
                fname = m_info['filename']
                
                start_time = f"{sub['start']}s"
                # æ™ºèƒ½æ—¶é•¿ï¼šå–å­—å¹•æ—¶é•¿å’Œç´ ææ—¶é•¿çš„æœ€å°å€¼
                duration = f"{min(sub['duration'], m_info['duration'])}s"
                
                try:
                    # ä¼˜å…ˆæ”¾åœ¨åŒä¸€ä¸ªè½¨é“
                    project.add_media_safe(path, start_time=start_time, duration=duration, track_name=target_track)
                    print(f"    [+] [{start_time}] (é•¿ {duration}) åŒ¹é…å­—å¹• {idx}: {sub['text'][:10]}... -> {fname}")
                    added_count += 1
                    used_materials.add(m_id) # æ ‡è®°ä¸ºå·²ä½¿ç”¨
                except Exception as e:
                    # å¦‚æœè¯¥ä½ç½®ç¡®å®æœ‰æç»†å¾®çš„é‡å å¯¼è‡´å¤±è´¥ï¼Œå†å°è¯•å¤‡ç”¨è½¨é“
                    try:
                        project.add_media_safe(path, start_time=start_time, duration=duration, track_name=f"{target_track}_Alt")
                        added_count += 1
                    except:
                        print(f"    [!] è·³è¿‡å†²çªç´ æ: {fname} at {start_time}")

        project.save()
        print(f"DONE: ç»„è£…å®Œæˆ! å·²ç²¾ç®€åŒ¹é…ï¼Œå…±æ·»åŠ  {added_count} ä¸ªç©ºé•œç´ æã€‚")

# ==========================================
# 4. æ‰§è¡Œå…¥å£ (Run)
# ==========================================
# ==========================================
# 4. æ‰§è¡Œå…¥å£ (CLI)
# ==========================================
import argparse

def str2bool(v):
    if isinstance(v, bool):
       return v
    if v.lower() in ('yes', 'true', 't', 'y', '1'):
        return True
    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
        return False
    else:
        raise argparse.ArgumentTypeError('Boolean value expected.')

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="è§†é¢‘å…¨è‡ªåŠ¨å‰ªè¾‘ï¼šè‡ªåŠ¨è¯­éŸ³è½¬å­—å¹• -> æ™ºèƒ½ç´ æåˆ†æ -> è¯­ä¹‰ç”»é¢åŒ¹é… -> å¯¼å‡ºå‰ªæ˜ è‰ç¨¿")
    
    # æ ¸å¿ƒè¾“å…¥å‚æ•° (æ”¯æŒå¤šç§ç»„åˆ)
    parser.add_argument("--video", type=str, help="ä¸»è§†é¢‘æˆ–ä¸»éŸ³é¢‘è·¯å¾„ (ç”¨äºè¯†åˆ«éŸ³é¢‘å¹¶ç”Ÿæˆå­—å¹•)")
    parser.add_argument("--srt", type=str, help="ç›´æ¥æä¾›å­—å¹•æ–‡ä»¶ (è·³è¿‡ AI è¯†åˆ«æ­¥éª¤)")
    
    # ç´ æè¾“å…¥ï¼šæ”¯æŒå¤šä¸ªæ–‡ä»¶å¤¹æˆ–æ–‡ä»¶
    parser.add_argument("--materials", type=str, nargs="+", required=True, 
                        help="ç´ ææ¥æºï¼Œå¯ä»¥ä¼ å…¥å¤šä¸ªæ–‡ä»¶å¤¹è·¯å¾„æˆ–å…·ä½“è§†é¢‘æ–‡ä»¶è·¯å¾„")
    
    # å¯é€‰å‚æ•°
    parser.add_argument("--project", type=str, default="AI_Auto_Edit_Project", help="å‰ªæ˜ è‰ç¨¿å·¥ç¨‹åç§°")
    parser.add_argument("--clear_cache", type=str2bool, default=False, help="æ˜¯å¦æ¸…é™¤ç¼“å­˜é‡æ–°åˆ†æ (True/False)")
    parser.add_argument("--limit", type=int, default=0, help="é™åˆ¶åˆ†æç´ æçš„æ•°é‡ (0 ä¸ºä¸é™åˆ¶)")
    parser.add_argument("--bg_image", type=str, default=None, help="éŸ³é¢‘æ¨¡å¼ä¸‹çš„èƒŒæ™¯(æ”¯æŒ white, black æˆ–å›¾ç‰‡è·¯å¾„)")

    args = parser.parse_args()

    # è·¯å¾„å¤„ç†
    main_input = os.path.abspath(args.video) if args.video else None
    srt_input = os.path.abspath(args.srt) if args.srt else None
    material_sources = args.materials
    
    if not main_input and not srt_input:
        parser.error("âŒ å¿…é¡»æä¾› --video (ä¸»è§†é¢‘/éŸ³é¢‘) æˆ– --srt (ç›´æ¥æä¾›å­—å¹•) å…¶ä¸­çš„è‡³å°‘ä¸€ä¸ªã€‚")

    if args.clear_cache:
        print("[Cleaning] æ¸…é™¤ç°æœ‰ç¼“å­˜æ–‡ä»¶...")
        for cache_file in ["auto_material_analysis.json", "auto_ai_matches.json", "auto_generated_subs.srt"]:
            p = os.path.join(WORKSPACE_ROOT, cache_file)
            if os.path.exists(p) and (not srt_input or cache_file != os.path.basename(srt_input)):
                os.remove(p)

    editor = VideoAutoEditor(main_input, material_sources, args.project, srt_input=srt_input, bg_image=args.bg_image)
    
    # 1. è¯†åˆ«å­—å¹• (å¦‚æœæ˜¯é€šè¿‡ --srt ä¼ å…¥çš„ä¼šç›´æ¥è·³è¿‡)
    editor.step1_recognize_subtitles()
    
    # 2. åˆ†æç´ æ
    limit = args.limit if args.limit > 0 else None
    m_data = editor.step2_analyze_materials(limit=limit)
    
    # 3. AI åŒ¹é…
    matches = editor.step3_ai_match(m_data)
    
    # 4. ç»„è£…
    editor.step4_assemble_project(m_data, matches)
